# Token-estimation-function (TEF)

Проект исследует и реализует модуль функции оценки токенов (token estimation function) на основе модели GPT-2.

## Идея TEF
Функция оценки токенов - это модуль, который дает оценку каждому токену последовательности. После присвоения своей оценки, токены проходят через фильтрацию. 
Например, отбирается топ-к наиболее высоко оценненных токенов, либо отбираются токены, преодолевающие определенный порог. 

Другая интерпретация: каждая оценка токена представляет его объясненную дисперсию. Фильтрация токенов происходит по порогу объясненной дисперсии.


### Реализация
1. Интерфейс модуля функции оценки токенов: `src/tefs/tef_scorer.py`
2. Бэкенд: `src/tefs_backend/tef_scorer/` 
3. Модель GPT-2 со встроенной функцией оценки токенов: `src/models/gpt2_tef.py`

### Бэкенд
Реализация бэкнда на torch `src/tefs_backend/tef_scorer/torch_backend.py` и на основе triton `src/tefs_backend/tef_scorer/triton_backend.py`  

На triton реализован кернел, "раскидывающий" токены после сортировки по нужным позициям.

Triton-реализация дает ~5% ускорения одной итерации на NVIDIA 3090


## Структура проекта
Основные директории:
- `src/models/` - обучаемые модели.
- `src/lightning_modules/` - Lightning-модули и обертки над моделями.
- `src/data/` - директория для датасетов (представлен только WikiText-103).
- `src/tefs/` и `src/tefs_backend/` - реализация TEF.
- `src/losses/` - aux loss'ы для обучения TEF.
- `configs/` - YAML-конфиги моделей, обучения и генерации.
- `scripts/training/` - скрипты для запуска обучения. Все частные скрипы опираются на общий скрипт `train.py`
- `scripts/evaluation/` - скрипты для генерация текстов и оценки результатов обучения.
- `scripts/benchmarks/` - бенчмарки для оценки triton-кернелов.
- `scripts/profiling/` - скрипт для профилирования.
- `tests/` - unit-тесты на `pytest`.

## Установка

Все зависимости для минимально работоспособной версии находятся в файле `requirements.txt`. 
Дополнительные зависимости (для разработки и тестирования) лежат в `requirements_dev.txt`

Для обучения на видеокартах NVIDIA нужно установить версию torch под свою конфигурацию.

## Старт
Для скриптов обязательно нужно задать `.env` с `CONFIG_DIR`:

```
CONFIGS_DIR="<путь до корня проекта>/configs"
```

### Обучение baseline
```bash
python scripts/training/autoregressive/train_gpt2.py
```

### Обучение GPT-2 + TEF
```bash
python scripts/training/autoregressive/train_gpt2_tef.py
```

### Логирование и артефакты
Логи и артефакты:
- TensorBoard: `logs/<task_name>/...`
- Checkpoints: `checkpoints/<project_name>/<task_name>/...`

Также в скриптах подключен ClearML

## Автотесты
Реализованы юнит-тесты на pytest. Из корня проекта:

```bash
pytest tests
```

## Постер
Репозиторий - часть проекта на AITH DemoDay. Постер с демо-дей лежит в `papers/`